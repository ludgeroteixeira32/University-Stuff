{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"uni.png\"\n",
    "     alt=\"Universidade Logo\" />\n",
    "<br>\n",
    "<br>\n",
    "# Aprendizagem Automática - 2 Trabalho \n",
    "\n",
    "##### Realizado por : \n",
    "- Rúben Wilson nº 39837 \n",
    "- Ludgero Teixeira nº 41348\n",
    "\n",
    "#### <ins>Objetivo do trabalho</ins>: \n",
    "\n",
    "Utilizando informação do histórico académico dos alunos(programa, ECTS matriculados e concluídos e notas médias),construir um modelo preditivo que responda à pergunta:\"quais os alunos em risco de abandonar os estudos?\"\n",
    "\n",
    "## Introdução\n",
    "Sendo o objetivo deste trabalho obter um modelo preditivo que responda de uma forma eficiente à pergunta <i>\"quais os alunos em risco de abandonar os estudos?\"</i>, começamos então por analisar as várias possibilidades de algoritmos a utilizar e quais seriam aqueles que iriam ao encontro do tipo de dados disponíveis e ao problema a resolver. Após esta análise avançamos com os algoritmos <b>RandomForest</b> e <b>LogisticRegression</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1º Modelo: Logistic Regression\n",
    "<br>\n",
    "\n",
    "### Imports\n",
    "\n",
    "Inicialmente começamos por realizar os imports necessários para a construção do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Dados\n",
    "\n",
    "Decidimos remover o atributo \"Program\" porque no nosso ponto de vista o tipo de curso a que cada aluno pertence não tem uma ligação direta para a criação de um modelo de previsão no âmbito de prever que alunos estão em risco de desistir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train.csv')\n",
    "test = pd.read_csv('test.csv')\n",
    "\n",
    "X = df.iloc[:, df.columns != 'Failure']\n",
    "del X['Program'] \n",
    "y = df['Failure']\n",
    "teste = test.iloc[:, test.columns != 'Program']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_test_split\n",
    "\n",
    "Usamos o método <b>train_test_split</b> para fazer a divisão do conjunto de dados na seguinte forma:\n",
    "- <b>Conjunto Dados de Treino</b>\n",
    "- <b>Conjunto Dados de Validação</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(X, y, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines \n",
    "\n",
    "São uma forma de executar vários processos na ordem em que estão listados.\n",
    "O objetivo do pipeline é reunir várias etapas que podem ser validadas em conjunto ao definir parâmetros diferentes.\n",
    "\n",
    "Neste Pipeline os parâmetros escolhidos são foram:\n",
    " - <b>StandardScaler():</b> Normaliza os atributos removendo a média e escala para variação unitária.\n",
    " - <b>LogisticRegression():</b> A regressão logística é uma técnica estatística que tem como objetivo produzir, a partir de um conjunto de observações, um modelo que permita a predição de valores tomados por uma variável categórica, frequentemente binária, a partir de uma série de variáveis explicativas contínuas e/ou binárias."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logpipe = Pipeline([('scale', StandardScaler()),('logr',LogisticRegression())])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param_grid\n",
    "\n",
    "Irá conter o conjunto de parâmetros do <i><b>Logistic Regression</b></i>, sendo estes os seguintes:\n",
    "- <b>C:</b> Inverso da força de regularização -> <b>10.01</b>\n",
    "- <b>solver:</b> Algoritmo a ser usado no problema de otimização. -> <b>lbfgs</b>\n",
    "- <b>multi_class:</b> um problema binário é adequado para cada label -> <b>ovr</b>\n",
    "- <b>penalty:</b> usado para especificar a norma usada na penalização -> <b>L2</b>\n",
    "\n",
    "Para chegar a estes valores usamos a seguinte estrutura:\n",
    "<br>\n",
    "`param_grid = [\n",
    "    {'logr__C':np.arange(0.01,100,10),\n",
    "     'logr__penalty': [\"l1\",\"l2\"]}\n",
    "]`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'logr__C':[10.01],\n",
    "    'logr__solver':['lbfgs'],\n",
    "    'logr__multi_class':['ovr'],\n",
    "    'logr__penalty':[\"l2\"]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV & Fit\n",
    "\n",
    "Usamos o <b>GridSearchCV</b> para realizar uma pesquisa exaustiva sobre valores de parâmetros especificados(param_grid) para um estimador(<b>LogisticRegression()</b>).\n",
    "Este usa os seguintes parâmetros:\n",
    "- <b>logregpipe:</b> Pipeline defina acima\n",
    "- <b>param_grid:</b> Conjunto de parâmetros a utilizar\n",
    "- <b>cv:</b> Determina a estratégia de divisão para a validação cruzada -> <b>10</b>\n",
    "\n",
    "Após efetuarmos o <b>GridSearchCV</b> precedemos ao <i><b>logpipe_cv.fit</b></i> atribuindo-o à variável <b>best_clf</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'logr__C': 10.01, 'logr__multi_class': 'ovr', 'logr__penalty': 'l2', 'logr__solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "logpipe_cv = GridSearchCV(logpipe , param_grid , cv = 10, return_train_score = True)\n",
    "best_clf = logpipe_cv.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print da Exatidão & Criação do conjunto de previsão\n",
    "\n",
    "Primeiro faz print da <b>exatidão(score)</b>, onde usando o nosso <b>modelo</b> e o <b>conjunto de validação (x_test, y_test)</b>.\n",
    "<br>\n",
    "O conjunto de previsão após ser calculado é guardado num ficheiro <i><b>LRprevisao.csv</b></i> numa coluna chamada previsões, sendo que para cada <i><b>id</b></i> do ficheiro <i><b>test</b></i> ele gera essa mesma previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A exatidão é de: 0.9437229437229437\n"
     ]
    }
   ],
   "source": [
    "print('A exatidão é de:',best_clf.score(X_val, y_val))\n",
    "prediction = pd.DataFrame(best_clf.predict(teste), columns=['previsoes']).to_csv('LRprevisoes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observações Finais deste modelo\n",
    "\n",
    "<b>Logistic Regression</b> como primeiro modelo de previsão testado apresentou logo bons resultados <i>(melhores do que estavamos à espera)</i> para o tipo de problema em mãos.\n",
    "Os parâmetros utilizados para a construção do modelo de previsão indicam ser os mais adequados, pois após várias tentativas entre escolha de parâmetros e de valores dos mesmos, aqueles que apresentaram melhores resultados mantiveram-se, sendo que a tentativa de arranjar outras formas de aumentar a exatidão do modelo não tiveram qualquer sucesso.\n",
    "Sendo que o valor de exatidão para o conjunto de teste flutua entre os <b>94%</b> e os <b>95%</b> é possível afirmar que foi feita uma boa previsão, não exedendo os valores ao ponto de haver <ins>overfitting</ins>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2º Modelo: Random Forest\n",
    "\n",
    "### Imports\n",
    "\n",
    "Inicialmente começamos por realizar os imports necessários para a construção do nosso modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tratamento de Dados\n",
    "\n",
    "De forma a encontrar os dados realmente necessários para o problema em causa e permitir construir o nosso modelo de uma melhor forma, acabamos por decidir para este modelo adaptar uma perspetiva diferente em relação à do modelo <b>LogisticRegression</b>.<br>\n",
    "Assim sendo, decidimos retirar inicialmente a coluna <i><b>\"Program\"</b></i> pela mesma razão que mencionamos no modelo do anterior e seguidamente todas as colunas denomidas por <i><b>\"..._grade\"</b></i> , isto porquê?\n",
    "<br>Porque, por um lado a média de cada aluno de cada semestre acaba por não ser uma feature decisiva para alguém desistir de um curso ou não, e se essa mesma média acabar por estar refletida já nos <b>ECTS</b> completados.<br>\n",
    "Por outro, imaginando um aluno inscrito a 36 ECTS e completa 2 ECTS, sendo que nesses dois obteve uma classificação de 18 valores a média que iria aparecer na coluna para esse mesmo aluno seria 18, logo acaba por ser uma média <b>\"Falsa\"</b> que nos pode levar a erros...\n",
    "\n",
    "- <b>train2.csv:</b> Ficheiro dados treino alterado segundo as razões mencionadas acima\n",
    "- <b>test2.csv:</b> Ficheiro dados teste alterado segundo as razões mencionadas acima\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('train2.csv')\n",
    "test = pd.read_csv('test2.csv')\n",
    "\n",
    "X = df.iloc[:, df.columns != 'Failure']\n",
    "\n",
    "y = df['Failure']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_test_split\n",
    "\n",
    "Usamos o método <b>train_test_split</b> para fazer a divisão do conjunto de dados na seguinte forma:\n",
    "- <b>Conjunto Dados de Treino</b>\n",
    "- <b>Conjunto Dados de Validação</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.28,random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipelines \n",
    "\n",
    "São uma forma de executar vários processos na ordem em que estão listados.\n",
    "O objetivo do pipeline é reunir várias etapas que podem ser validadas em conjunto ao definir parâmetros diferentes.\n",
    "No modelo abaixo, definimos o <i><b>Random Forest Classifier</b></i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('classifier', RandomForestClassifier())]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Param_grid\n",
    "\n",
    "Irá conter o conjunto de parâmetros do <i><b>RandomForest</b></i>, sendo estes os seguintes:\n",
    "- <b>n_estimators:</b> O número de árvores -> <b>80</b>\n",
    "- <b>criterion:</b> Critério usado para medir a qualidade de uma divisão -> <b>entropy</b>\n",
    "- <b>max_features:</b> O número de features a serem considerados ao procurar a melhor divisão -> <b>18</b>\n",
    "\n",
    "Para chegar a estes valores usamos a seguinte estrutura:\n",
    "<br>\n",
    "`param_grid = [\n",
    "    {'classifier__n_estimators':  list(range(10, 101, 10)),\n",
    "     'classifier__criterion': ['entropy','gini'],\n",
    "     'classifier__max_features': list(range(1,31))}\n",
    "]`\n",
    "<br>\n",
    "Sendo que depois de efetuarmos o <i><b>GridSearchCV</b></i> e o método <i><b>fit</b></i> usamos o `print(best_clf.best_params_)` para encontrar esses mesmo valores!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [\n",
    "    {'classifier__n_estimators': [80],  \n",
    "     'classifier__criterion': ['entropy'],\n",
    "     'classifier__max_features': [18]}]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV & Fit\n",
    "\n",
    "Usamos o <b>GridSearchCV</b> para realizar uma pesquisa exaustiva sobre valores de parâmetros especificados(param_grid) para um estimador(<b>RandomForestClassifier()</b>).\n",
    "Este usa os seguintes parâmetros:\n",
    "- <b>pipe:</b> Pipeline definida acima\n",
    "- <b>param_grid:</b> Conjunto de parâmetros a utilizar\n",
    "- <b>cv:</b> Determina a estratégia de divisão para a validação cruzada -> <b>5</b>\n",
    "\n",
    "Após efetuarmos o <b>GridSearchCV</b> procedemos ao <i><b>clf.fit</b></i> atribuindo-o à variável <b>best_clf</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of   5 | elapsed:    2.7s finished\n"
     ]
    }
   ],
   "source": [
    "clf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=True, n_jobs=-1)\n",
    "best_clf = clf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print da Exatidão & Criação do conjunto de previsão\n",
    "\n",
    "Primeiro faz print da <b>exatidão(score)</b>, onde usando o nosso <b>modelo</b> e o <b>conjunto de validação (x_test, y_test)</b>.\n",
    "<br>\n",
    "O conjunto de previsão após ser calculado é guardado num ficheiro <i><b>previsoes2.csv</b></i> numa coluna chamada previsoes, sendo que para cada <i><b>id</b></i> do ficheiro <i><b>test</b></i> ele gera essa mesma previsão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A exatidão é de: 0.9458413926499033\n"
     ]
    }
   ],
   "source": [
    "print('A exatidão é de:',best_clf.score(x_val, y_val))\n",
    "\n",
    "prediction = pd.DataFrame(best_clf.predict(test), columns=['previsoes']).to_csv('RFprevisoes.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observações Finais deste modelo\n",
    "\n",
    "Apresenta ser um modelo eficaz para este tipo de problema sendo que com esta parametrização obtemos valores de exatidão entre <b>94% - 96%</b>.\n",
    "No entanto tentámos efetuar e encontrar outros parâmetros que nos permitissem obter valores de exatidão mais elevados mas essas mesmas tentivas não tiveram qualquer sucesso...\n",
    "<br>Uma das causas possíveis para o não sucesso da respetiva melhoria será a forma como tratamos os dados inicialmente, possivelmente olhando, alterando e criando dados novos e mais eficientes como base nos dados iniciais, ou seja, <b>uma perspetiva diferente</b> do que aquela que decidimos traçar, muito possivelmente teriamos obtido resultados no que se trata na melhoria dos valores de exatidão."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bibliografias\n",
    "\n",
    "- https://scikit-learn.org/stable/modules/grid_search.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html\n",
    "- https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
